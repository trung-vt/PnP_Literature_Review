% ============================================================
% Review on Plug-and-Play (PnP) Methods
% ============================================================

\documentclass[11pt,a4paper]{article}

% ---------- Packages ----------
\usepackage[british]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{microtype}
\usepackage{setspace}
\onehalfspacing

\usepackage{amsmath,amssymb,mathtools,amsthm}
\numberwithin{equation}{section}

\usepackage{bm}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage[
    skip=1pt,
    % font=tiny
]{subcaption} % for subfigures
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{hyperref}
\geometry{margin=1in}
\usepackage[nottoc]{tocbibind} % Include bibliography in ToC
\usepackage[%
    backend=biber,
    natbib=true,
    style=alphabetic,
    maxnames = 100,
]{biblatex}
\addbibresource{references.bib}
\usepackage[nameinlink,capitalize]{cleveref}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% ---------- Hyperref ----------
\hypersetup{
    colorlinks=true,
    linkcolor=blue!40!black,
    citecolor=blue!40!black,
    urlcolor=blue!40!black,
    pdfauthor={\textbf{Thanh Trung Vu}},
    pdftitle={Plug-and-Play Methods in Inverse Problems: A Review}
}

% ---------- Macros (notation preferences) ----------
% Iteration index style (\cdot)^{(t)}
\newcommand{\iter}[1]{#1^{(t)}}
\newcommand{\itern}[2]{#1^{(t+#2)}}

% Cost function E (not J)
\newcommand{\E}{E}

% Linear forward operator and variables
\newcommand{\A}{A}
\newcommand{\uvec}{u}
\newcommand{\fvec}{f}
\newcommand{\noise}{\varepsilon}

% Proximal and denoiser
\newcommand{\prox}{\mathrm{prox}}
\newcommand{\Denoise}{\mathcal{D}}
\newcommand{\Lips}{L}

% Operators and sets
\newcommand{\R}{\mathbb{R}}
\newcommand{\Id}{\mathrm{Id}}

% TODO marker
\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}

% ---------- Theorem-like environments ----------
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{definition}{Definition}[section]

% ============================================================
\begin{document}

\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}
Plug-and-Play (PnP) methods are algorithms for solving inverse problems in imaging.

% They combine:
% (i) a known physical measurement model (the forward model), and
% (ii) an image denoiser (often very strong, sometimes learned).

The key idea: instead of writing an explicit prior (a hand-designed regulariser),
PnP uses the denoiser to provide prior information.

Early PnP methods were introduced in \cite{venkatakrishnan2013globalsip,venkatakrishnan2013tr},
and they were quickly used in many imaging problems
\cite{sreehari2016tci,rond2016poisson,yazdanpanah2019mri}.

For a broad tutorial overview of PnP methods, variations, and current practice, see \cite{kamilov2023spm}.

\section*{Inverse problems}
\addcontentsline{toc}{section}{Inverse problems and a basic formulation}
We observe measurements $y$ that are related to the unknown image $x$ by
$$
y = A x + \varepsilon,
$$
where $A$ is the forward operator and $\varepsilon$ is noise.
To recover $x$ from $y$, a common approach is to solve an optimisation problem.
We choose:
\begin{itemize}
    \item a data-fidelity term $f(x)$, which measures how well $A x$ matches $y$, and
    \item a prior term $g(x)$, which encourages $x$ to look like a realistic image.
\end{itemize}
A standard objective is
$$
\hat{x} \in \arg\min_x \; f(x) + \lambda g(x),
$$
where $\lambda > 0$ controls the strength of the prior.

PnP keeps the data term $f(x)$, but it does not need an explicit formula for $g$.
Instead, it uses a denoiser $D_\sigma(\cdot)$ (with noise level parameter $\sigma$)
as a replacement for the proximal step of $g$.

\section*{Common algorithm structures for PnP}
\addcontentsline{toc}{section}{Common algorithm structures for PnP}

\subsection*{PnP-ADMM and PnP-HQS}
\addcontentsline{toc}{subsection}{PnP-ADMM and PnP-HQS}
Many PnP methods start by splitting the problem into two variables.
Introduce an auxiliary variable $v$ and enforce $x=v$:
$$
\min_{x,v}\; f(x) + \lambda g(v) \quad \text{s.t. } x=v.
$$
Algorithms such as ADMM or HQS then alternate between updates for $x$ and updates for $v$.
In PnP-ADMM, the update for $v$ would normally be a proximal step of $g$,
but PnP replaces that step by a denoiser:
$$
v^{(k+1)} \approx D_\sigma(\,\cdot\,).
$$
This idea is analysed and used for image restoration in \cite{chan2017pnpadmm}.
There are also variants that try to reduce manual parameter tuning, for example
parameter-free versions \cite{wang2017parameterfree}.

\subsection*{PnP-FBS / PnP-PGD}
\addcontentsline{toc}{subsection}{PnP-FBS / PnP-PGD}
Another common structure is forward-backward splitting.
In each iteration, we first take a gradient step to reduce the data term $f(x)$,
and then we apply the denoiser:
$$
x^{(k+1)} = D_\sigma\!\Bigl(x^{(k)} - \gamma \nabla f(x^{(k)})\Bigr),
$$
where $\gamma > 0$ is a step size.

This form is studied with convergence guarantees under suitable assumptions on the denoiser
\cite{ryu2019icml,nair2021fixedpoint}.

Here, $D_\sigma$ can be any denoiser.
A useful special case is when the denoiser itself is defined by one gradient step on a learned energy; see the discussion below.

\subsection*{Consensus equilibrium viewpoint}
\addcontentsline{toc}{subsection}{Consensus equilibrium viewpoint}
PnP does not always correspond to minimising a single explicit objective function.
An alternative way to understand PnP is the consensus equilibrium (CE) viewpoint \cite{buzzard2018ce}.

In CE, we look for a point where two operators agree:
one operator comes from the data model (the forward problem),
and the other operator is the denoiser.
This idea is formalised in \cite{buzzard2018ce}, and it is useful when combining
multiple priors or multiple agents.

\section*{What does the denoiser mean as a prior?}
\addcontentsline{toc}{section}{What does the denoiser mean as a prior?}
There are two main ways to interpret the role of the denoiser:
\begin{itemize}
    \item \textbf{Implicit prior (fixed-point view).}
    PnP defines an iterative algorithm, and the final reconstruction is typically a fixed point
    of the update rule. In general, this fixed point does not have to be the minimiser of
    $f(x) + \lambda g(x)$ for any explicit function $g$ \cite{buzzard2018ce,ryu2019icml}.
    \item \textbf{Explicit objective (RED view).}
    Regularization by Denoising (RED) builds an explicit regulariser from the denoiser.
    Later works clarify when this objective is mathematically well-defined and when it is not
    \cite{romano2017red,reehorst2018red,reehorst2019tci}.
\end{itemize}

\paragraph*{Interpretability: what prior does a denoiser represent?}
A common question is: what does the denoiser mean as a prior model?

One useful answer comes from a Bayesian view.
If $D_\sigma$ is (approximately) an MMSE denoiser for additive Gaussian noise,
then $D_\sigma(x) - x$ can be related to a smoothed \emph{score function}
(the gradient of the log-prior), via the Tweedie formula.
This connects PnP to an implicit probability model and helps explain why some PnP updates
look like gradient steps on an implicit energy.
This idea is used explicitly in Bayesian PnP methods that do posterior sampling (and not only point estimation)
\cite{laumont2022pnpula,reehorst2019red,park2024scorepnp}.


\section*{Convergence theory: which assumptions are used?}
\addcontentsline{toc}{section}{Convergence theory: which assumptions are used?}
Because PnP uses a denoiser that is not always a true proximal operator,
convergence analysis usually requires extra assumptions.
Common assumptions include:
\begin{itemize}
    \item \textbf{Lipschitz or nonexpansive denoisers.}
    Some results require the denoiser to be Lipschitz continuous, sometimes with a constant
    at most $1$, and then one can prove fixed-point convergence for certain PnP algorithms
    \cite{ryu2019icml}.
    \item \textbf{Bounded denoisers and continuation.}
    Some analyses assume the denoiser outputs do not change too much and use continuation
    (changing parameters gradually) to improve stability in practice \cite{chan2017pnpadmm}.
    \item \textbf{Proximal denoisers.}
    Another approach is to design or train the denoiser so that it behaves like a proximal map
    of some (possibly weakly convex) regulariser. This can give stronger convergence guarantees
    and allows faster methods, such as quasi-Newton ideas \cite{hurault2022icml,hurault2024jmiv,tan2024qn}.
\end{itemize}

\subsection*{Gradient-step denoisers (a structured denoiser)}
\addcontentsline{toc}{subsection}{Gradient-step denoisers (a structured denoiser)}
Most PnP papers treat the denoiser $D_\sigma$ as a black box.
Gradient-step denoisers are more structured: the denoiser is defined by one gradient descent step
on a learned energy function $\phi_\theta : \R^n \to \R$:
$$
D_{\eta,\theta}(x) = x - \eta \nabla \phi_\theta(x),
$$
where $\eta > 0$ is a step size (inside the denoiser) and $\theta$ are learnable parameters
\cite{hurault2021gsd,hurault2022icml}.

\paragraph*{Why this form is useful.}
This design makes the denoiser closer to an explicit regularisation model.
In particular, if $\nabla \phi_\theta$ is Lipschitz and $\eta$ is small enough,
then $D_{\eta,\theta}$ is also Lipschitz, and it can often be made stable in a way that is easier to analyse.
This can simplify convergence arguments for PnP algorithms, compared to using an unrestricted denoiser
\cite{hurault2022icml,hurault2024jmiv}.

\paragraph*{Connection to proximal denoisers.}
A proximal denoiser is a denoiser that behaves like a proximal map of some regulariser.
Gradient-step denoisers can be seen as an intermediate option:
they do not require computing a full proximal map, but they still introduce an explicit energy function
through $\phi_\theta$.
This idea is used to build convergent PnP methods with weaker assumptions on the denoiser
\cite{hurault2022icml,hurault2024jmiv}.

\paragraph*{Practical choices.}
In practice, $\eta$ controls the denoising strength in a direct way.
One can treat $(\eta,\theta)$ as the denoiser parameters and tune or learn them together.
It is also common to control smoothness (for example, by constraining Lipschitz constants)
to improve stability and convergence behaviour \cite{hurault2022icml}.

Related work also studies faster convergent PnP updates (for example quasi-Newton style variants) once the denoiser has suitable structure \cite{tan2024qn}.

\section*{Choosing parameters: step sizes, penalties, and denoiser strength}
\addcontentsline{toc}{section}{Choosing parameters: step sizes, penalties, and denoiser strength}
PnP methods have parameters from the optimisation algorithm (for example step size $\gamma$,
or an ADMM penalty parameter) and also parameters of the denoiser (for example $\sigma$).
These parameters strongly affect reconstruction quality and stability.

Some methods aim to reduce manual tuning, for example tuning-free PnP approaches
\cite{wei2022tfpnp}.
In practice, it is common to discuss:
continuation schedules, stopping rules, and sensitivity to parameter mismatch.

\section*{Applications and measurement models}
\addcontentsline{toc}{section}{Applications and measurement models}

\subsection*{Electron tomography and sparse interpolation}
\addcontentsline{toc}{subsection}{Electron tomography and sparse interpolation}
PnP was used in electron tomography and sparse interpolation problems in \cite{sreehari2016tci}.
This shows that PnP can exploit repeated structures in images even when measurements are limited.

\subsection*{Poisson and photon-limited imaging}
\addcontentsline{toc}{subsection}{Poisson and photon-limited imaging}
In photon-limited imaging, the noise is often modelled by a Poisson distribution.
PnP methods have been adapted to this setting, for example using appropriate data-fidelity terms
and stabilisation techniques \cite{rond2016poisson}.

\subsection*{Nonlinear forward models}
\addcontentsline{toc}{subsection}{Nonlinear forward models}
Some imaging systems are nonlinear, meaning that $y$ is not a linear function of $x$.
PnP can still be used by combining denoisers with iterative methods designed for nonlinear
data terms \cite{kamilov2017nonlinear}.

\subsection*{MRI reconstruction}
\addcontentsline{toc}{subsection}{MRI reconstruction}
PnP has also been used for accelerated MRI reconstruction, including parallel MRI setups,
often by using deep denoisers inside an iterative solver \cite{yazdanpanah2019mri}.

\section*{Scalability: large problems, online methods, and stochastic updates}
\addcontentsline{toc}{section}{Scalability: large problems, online methods, and stochastic updates}
For large-scale problems, applying a strong denoiser many times can be expensive.
To reduce computation, there are online and stochastic versions of PnP that use
smaller batches of data or cheaper updates at each iteration \cite{sun2019onlinepnp,tang2020stochastic}.
These methods aim to keep reconstruction quality while reducing runtime.

\section*{Connections to denoising-based AMP}
\addcontentsline{toc}{section}{Connections to denoising-based AMP}
Approximate Message Passing (AMP) is another family of algorithms that uses denoisers as priors.
In denoising-based AMP, the denoiser is used inside an iterative method that can sometimes be
analysed using state evolution \cite{metzler2016damp}.
There are also learned versions that train parts of the algorithm \cite{metzler2017ldamp}.
When the sensing model is not i.i.d.\ Gaussian, VAMP-type methods are often more robust
\cite{schniter2016dvamp}, and extensions study effective coloured noise in compressive MRI
\cite{metzler2020dvdamp}.

\section*{Future directions}
\addcontentsline{toc}{section}{Summary and open problems}
PnP methods are popular because they combine physical models with strong denoisers.
However, there are still important open questions.
\begin{itemize}
    \item \textbf{Which convergence assumptions are realistic.} Convergence guarantees often require
    assumptions on the denoiser, and it is important to understand when these assumptions hold in practice
    \cite{ryu2019icml,hurault2024jmiv,tan2024qn}.

    \item \textbf{Practical issues.} Parameter tuning, robustness to dataset shift, uncertainty quantification,
    and standard benchmarking remain active topics \cite{kamilov2023spm,kamilov2022pnp}.

    \item \textbf{Uncertainty quantification (UQ).}
    Most PnP methods output one reconstruction (a point estimate), but many applications need an uncertainty estimate,
    for example pixel-wise credibility or uncertainty in derived quantities.

    A promising direction is Bayesian PnP, where a denoiser is used inside a sampling algorithm (for example Langevin-type sampling)
    to produce many samples and then estimate posterior mean, variance, and credible intervals
    \cite{laumont2022pnpula}.

    An open issue is \emph{calibration under mismatch}: the uncertainty can be misleading if the forward model,
    noise model, or denoiser training distribution do not match the real experiment
    \cite{renaud2024mismatch}.

    There are also works that explicitly target model uncertainty in a PnP-style pipeline
    \cite{ekmekci2021pnp_uq,terris2023pnp_uq_radio}.

    \item \textbf{PCM (photocurrent mapping) and realistic measurement effects.}
    For Photocurrent Mapping (PCM), practical effects such as pattern pairing, drift, calibration errors,
    and device-dependent noise can matter.

    Open questions include: accurate forward and noise models, sampling design, and fair evaluation when ground truth is limited.

    This is also a setting where interpretability (what features the prior promotes) and UQ (how confident the reconstruction is)
    can be especially important.
\end{itemize}


\printbibliography


\end{document}
